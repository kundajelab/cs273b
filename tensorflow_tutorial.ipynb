{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Introduction to TensorFlow ## \n",
    "\n",
    "(Much of this material is originally from cs224d TensorFlow tutorial by Bharath Ramsundar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TensorFlow logo](tutorial_images/tensorflow.png)\n",
    "\n",
    "TensorFlow provides primitives for defining functions on tensors and automatically computing their derivatives. \n",
    "\n",
    "* TensorFlow is a deep learning library for Python that has been recently open-sourced by Google. \n",
    "* TensorFlow has better support for distributed systems than many other competing libraries (i.e. Theano). \n",
    "* Keras (next tutorial) is a  high-level library that builds on TensorFlow. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a tensor? ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensor definition](tutorial_images/tensor_definition.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are some similarities between TensorFlow and Numpy ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Both TensorFlow and Numpy are N-d array libraries \n",
    "* Numpy does not have methods to create tensor functions and automatically compute derivatives. \n",
    "* Numpy does not have GPU support, but TensorFlow does. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy: ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.zeros((2,2)); b=np.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(b,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape(a,(1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same commands in TensorFlow:###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We just created an interactive Session. A Session object encapsulates the environment in which tensors are evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " a = tf.zeros((2,2)); b = tf.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " tf.reduce_sum(b, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.reduce_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " a.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that TensorShape behaves like a Python  tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " tf.reshape(a, (1, 4)).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a Numpy to TensorFlow dictionary: \n",
    "![Numpy To TensorFlow dictionary](tutorial_images/numpy_to_tensorflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow requires explicit evaluation ##\n",
    "TensorFlow computations define a computation graph that has no value until evaluated. Specifically TensorFlow programs usually have two phases: \n",
    "\n",
    "* construction phase -- assembles the computation graph \n",
    "* evaluation phase -- uses a Session to execute operations in the graph ; all computations add nodes to the global default graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in Numpy: \n",
    "a=np.zeros((2,2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#but in TensorFlow\n",
    "ta=tf.zeros((2,2))\n",
    "print(ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, we evaluate the computation graph: \n",
    "print(ta.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Sessions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.compat.v1.Session() as sess: \n",
    "    a=tf.constant(5.0)\n",
    "    b=tf.constant(6.0)\n",
    "    c=a*b \n",
    "    print(sess.run(c))\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tf.compat.v1.InteractiveSession()``` is convenient syntax for keeping a default session open in iPython. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables ##\n",
    "\n",
    "Variables are in-memory buffers that contain tensors. They are used to  hold and update parameters when a model is trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    W1 = tf.ones((2,2))\n",
    "    W2 = tf.Variable(tf.zeros((2,2)), name=\"weights\")    \n",
    "    print(sess.run(W1))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(W2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike constant tensors, TensorFlow variables must be initialized before they have values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable objects can be initialized from either constants or random values: \n",
    "W=tf.Variable(tf.zeros((2,2)), name=\"weights\") # initialized from zero values \n",
    "R=tf.Variable(tf.random_normal((2,2)), name=\"random_weights\") #initialized from random values \n",
    "\n",
    "#initialize all variables with values specified above: \n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(W))\n",
    "    print(sess.run(R))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating variable state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "#new_value = state + 1\n",
    "new_value = tf.add(state, tf.constant(1))\n",
    "\n",
    "#state=new_value\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #state=0 \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #print(state)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        #state=state+1\n",
    "        sess.run(update)\n",
    "        #print(state)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching variable state: \n",
    "\n",
    "* Calling ```sess.run(var)``` on a ```tf.Session()``` object retrieves its value. \n",
    "* We can retrieve multiple variables simultaneously with ```sess.run([var1,var2])```\n",
    "\n",
    "For example, let's evaluate the following computational graph: \n",
    "![Computation Graph Eval Example](tutorial_images/comp_graph_eval.png) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = tf.add(input2, input3)\n",
    "prod = tf.multiply(input1, intermed)\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([prod, intermed])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data inputs to TensorFlow: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data from a numpy array with \"convert_to_tensor\" function \n",
    "a=np.zeros((3,3))\n",
    "ta=tf.convert_to_tensor(a)\n",
    "with tf.Session() as sess: \n",
    "    print(sess.run(ta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more scalable approach: \n",
    "* use ```tf.placeholder``` variablesl (dummy nodes that provide entry points for data to the computational graph) \n",
    "* a ```feed_dict``` is a Python dictionary mapping from ```tf.placeholder``` variables to data \n",
    "\n",
    "![placeholders and feed forward dictionaries](tutorial_images/placeholder_feedforward_dict.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define placeholder objects for data entry \n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1,input2)\n",
    "with tf.Session() as sess: \n",
    "    #fetch value of output from computational graph and \n",
    "    #feed data into the computational graph \n",
    "    print(sess.run([output], feed_dict={input1:[7.],input2:[2.]}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable scope is necessary to avoid name clashes between variables in complex models. \n",
    "* ```tf.variable_scope()``` provides simple name-spacing \n",
    "* ```tf.get_variable()``` creates/accesses variables from within a variable scope "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting a variable's scope adds the corresponding prefix to the variable name \n",
    "with tf.variable_scope(\"foo\",reuse=None):\n",
    "    with tf.variable_scope(\"bar\",reuse=None):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "assert v.name == \"foo/bar/v:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\",reuse=None):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "assert v1 == v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```get_variable()``` will behave differently depending on whether or not reuse is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case 1: reuse is set to false \n",
    "# A new variable is created and returned -- but this will give an error if the variable already exists in this scope, \n",
    "#as is the case here \n",
    "\n",
    "#with tf.variable_scope(\"foo\"): \n",
    "#    v=tf.get_variable(\"v\", [1])\n",
    "#assert v.name==\"foo/v:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case 2: reuse is set to true \n",
    "# search for existing variable with a given name \n",
    "#raise ValueError if none is found \n",
    "with tf.variable_scope(\"foo\", reuse=True):\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "assert v1 == v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports auto-differentiation to compute gradients without user input.\n",
    "* ```tf.train.Optimizer``` creates an optimizer. \n",
    "* ```tf.train.Optimizer.minimize(loss, var_list)``` adds optimization operation to the computation graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out TensorBoard for visualizing the computational graph and training metrics: https://www.tensorflow.org/versions/r0.11/how_tos/summaries_and_tensorboard/index.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST ConvNet Example ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Convolutional Network implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
